import { client, q } from '../src/fauna_client';
import { getRarityForDopeId } from '../src/dope_rarity_check';
import DopeJson from 'dope-metrics/output/loot.json';
import chunkArray from '../src/chunk_array';

// Returns data structures that should map to the GraphQL schema for DopeToken
// as defined in dope_token_schema.graphql
const buildTokenObjects = () => {
  console.log('Building token objects');
  const lootJsonEntries = Object.entries(DopeJson);
  const tokens = [];
  for (let i = 0; i < lootJsonEntries.length; i++) {
    const dopeAsset = lootJsonEntries[i][1];
    const tokenId = Object.keys(dopeAsset)[0];
    const itemValues = Object.values(dopeAsset)[0];
    const tokenDocument = Object.assign(
      {
        token_id: tokenId,
        // Merge items we have with smart defaults we can update later.
        // Default paper_claimed / items_unbundled to worst possible status
        // and update from The Graph later.
        paper_claimed: true,
        items_unbundled: true,
        rank: getRarityForDopeId(tokenId)
      }, 
      itemValues
    );
    // Adding tokenId to nested array allows us to use it as 
    // the Fauna "ref" instead of an autogenerated one they create.
    tokens.push([tokenId, tokenDocument]);
  }
  return tokens;
}

const populate = async(tokens: any[]) => {
  console.log(`Populating ${tokens.length} DOPE tokens`)
  await client.query(
    q.Map(
      tokens, 
      q.Lambda(
        ['token_id', 'data'], 
        q.Create(
          q.Ref(q.Collection('DopeToken'), q.Var('token_id')),
          { data: q.Var('data') }
        )
      )
    )
  );
  console.log('Done');
};

(async () => {
  try {
    const tokens = buildTokenObjects();
    // Chunk tokens into sections to avoid timeout
    const tokenChunks = chunkArray(tokens, 250);
    for (const chunk of tokenChunks) {
      await populate(chunk);
    }
    process.exit(0);
  } catch (e) {
    console.error(e);
    process.exit(1);
  }
})();
